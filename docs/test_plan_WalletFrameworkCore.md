# Test Plan: WalletFrameworkCore

## 1. Introduction

This document outlines the test plan for the WalletFrameworkCore feature within the wallet-framework-dotnet project. The primary goal of this test plan is to ensure the quality, reliability, security, and performance of the core wallet functionalities, aligning directly with the project's overarching AI-Verifiable End Results of achieving maximum code coverage, maintaining a fast and secure codebase, and adhering to a Test-Driven Development (TDD) approach.

The scope of this test plan covers the core components and interactions described in the project's architecture, focusing on the fundamental operations of a digital wallet framework.

## 2. Test Scope and AI-Verifiable End Results

The test scope is defined by the core functionalities of the WalletFrameworkCore, as understood from the project's architecture and the implicit Master Project Plan goals. The tests will specifically target the verification of the following AI-Verifiable End Results:

*   **AI-VERIFIABLE OUTCOME: High Code Coverage:** Achieve and maintain a high percentage of code coverage for the WalletFrameworkCore codebase, verifiable via code coverage reports generated by Coverlet.
*   **AI-VERIFIABLE OUTCOME: Successful Core Operations:** Ensure that fundamental wallet operations (e.g., wallet creation, key management, credential storage, signing) execute correctly and produce expected outcomes under various conditions.
*   **AI-VERIFIABLE OUTCOME: Secure Interactions:** Verify that interactions between components and with external systems (when applicable) adhere to security protocols and prevent common vulnerabilities, verifiable through passing security-focused tests.
*   **AI-VERIFIABLE OUTCOME: Performance Efficiency:** Confirm that core operations meet defined performance criteria (though specific performance metrics are not detailed in the provided architecture, tests will aim for efficient execution), verifiable through test execution times and potential future performance tests.
*   **AI-VERIFIABLE OUTCOME: TDD Adherence:** Demonstrate that tests are written following TDD principles, focusing on behavior and outcomes, verifiable through test structure and implementation style.

## 3. Test Strategy: London School of TDD and Layered Testing

The testing strategy for WalletFrameworkCore is firmly rooted in the London School of TDD. This approach emphasizes testing the behavior of a unit through its interactions with its collaborators, rather than inspecting its internal state. Collaborators will be mocked or stubbed to isolate the unit under test and verify that it sends the correct messages to its dependencies and reacts appropriately to their responses.

A layered testing approach will be employed:

*   **Unit Tests:** These form the foundation, focusing on individual classes or small groups of related classes. Using xUnit as the testing framework and Moq for mocking, these tests will verify the unit's behavior by asserting on the interactions with mocked collaborators and the observable outcomes produced by the unit. These tests are designed to be fast and provide rapid feedback.
*   **Integration Tests:** These tests verify the interactions between multiple components or services. While still potentially using mocks for external system boundaries (like databases or external APIs), they will test the integration logic between internal components. WebApplicationFactory can be used for testing ASP.NET Core components if the WalletFrameworkCore integrates with such a layer.
*   **End-to-End / BDD Tests:** These tests validate the system's behavior from a user's perspective, often described using Gherkin syntax (Given-When-Then). SpecFlow will be used to facilitate Behavior-Driven Development, ensuring the system meets the specified requirements. These tests will involve larger parts of the system and potentially interact with real external dependencies or test doubles that simulate the external environment.
*   **Property-Based Tests:** FsCheck can be utilized to generate test data based on properties that the code should satisfy. This helps in discovering edge cases that might be missed with example-based testing.

This layered approach, combined with London School principles, ensures that issues are identified at the lowest possible layer, providing faster feedback and easier debugging.

## 4. Recursive Testing Strategy

A comprehensive recursive testing strategy is crucial for maintaining the quality and stability of the WalletFrameworkCore over time and catching regressions early. The test suites (or relevant subsets) will be re-executed at various Software Development Life Cycle (SDLC) touch-points:

*   **Per-Commit / Continuous Integration (CI):** A fast-running subset of critical unit tests and key integration tests will be executed on every commit to the version control system. This provides immediate feedback on whether recent changes have introduced regressions in core functionalities. Tests suitable for this level will be tagged appropriately (e.g., `[Category("Fast")]`, `[Category("CI")]`).
*   **End-of-Sprint:** A more comprehensive suite, including most unit and integration tests, will be run at the end of each development sprint. This ensures the stability of the features developed during the sprint. Tests for this level might be tagged `[Category("Sprint")]`.
*   **Pre-Release:** A full test suite, including all unit, integration, and end-to-end/BDD tests, will be executed before any release candidate is built. This provides a high level of confidence in the overall system stability. These tests might be tagged `[Category("Release")]`.
*   **Post-Deployment / Hot-fixes / Patches / Configuration Changes:** A targeted set of tests related to the specific changes deployed will be executed immediately after deployment or applying fixes/configuration changes. This verifies that the changes have not introduced new issues in the production environment. These tests will be selected based on the affected components and might use specific tags or test selection criteria.
*   **Scheduled Nightly/Weekly Runs:** The full test suite will be executed on a scheduled basis (e.g., nightly or weekly) to detect regressions that might not be caught by the faster CI runs or to identify performance degradation over time.
*   **Integration of New Modules or Third-Party Services:** When new modules are integrated or third-party services are updated, relevant integration and end-to-end tests will be re-executed to ensure compatibility and correct interaction.
*   **Dependency or Environment Upgrades:** After upgrading project dependencies or making changes to the development/testing environment, a significant portion of the test suite, particularly integration and end-to-end tests, will be re-executed to verify compatibility.

**Test Selection and Tagging:**

Tests will be tagged using attributes (e.g., `[Category("Fast")]`, `[Category("CI")]`, `[Category("Sprint")]`, `[Category("Release")]`, `[Category("Security")]`, `[Category("Performance")]`) to facilitate efficient selection for different recursive testing triggers. Test runners (like the `dotnet test` CLI with filtering options) will be configured to execute specific subsets of tests based on these tags.

**Layered Testing in Regression:**

The recursive strategy will consider the layered testing approach. Changes in lower layers (unit level) might only require re-running unit tests and potentially related integration tests. Changes in higher layers (integration or E2E) will necessitate re-running tests at that layer and potentially a subset of lower-layer tests if the changes impact fundamental component interactions.

## 5. Test Cases

This section outlines example test cases, demonstrating the application of London School principles and their mapping to AI-Verifiable End Results. Specific test cases will be developed based on detailed feature requirements as they become available.

**Example Test Case 1: Successful Wallet Creation**

*   **AI-Verifiable End Result Targeted:** Successful Core Operations, High Code Coverage, TDD Adherence.
*   **Unit Under Test:** `WalletService` (hypothetical)
*   **Interactions to Test:** The `WalletService`'s interaction with a storage mechanism when creating a new wallet.
*   **Collaborators to Mock:** `IWalletStorage` (hypothetical interface for storage operations).
*   **Expected Interactions with Mocks:** The `WalletService` should call the `IWalletStorage.SaveWallet(walletData)` method exactly once with the correct wallet data.
*   **Observable Outcome:** The `WalletService.CreateWallet()` method should return a unique wallet identifier upon successful creation.
*   **Recursive Testing Scope:** Included in `[Category("Fast")]`, `[Category("CI")]`, `[Category("Sprint")]`, `[Category("Release")]`.

**Example Test Case 2: Retrieving a Stored Credential**

*   **AI-Verifiable End Result Targeted:** Successful Core Operations, High Code Coverage, TDD Adherence.
*   **Unit Under Test:** `CredentialService` (hypothetical)
*   **Interactions to Test:** The `CredentialService`'s interaction with a storage mechanism to retrieve a specific credential.
*   **Collaborators to Mock:** `ICredentialStorage` (hypothetical interface for credential storage).
*   **Expected Interactions with Mocks:** The `CredentialService` should call `ICredentialStorage.GetCredential(credentialId)` with the provided credential identifier. The mock should be configured to return a predefined credential object.
*   **Observable Outcome:** The `CredentialService.GetCredential(credentialId)` method should return the expected credential object.
*   **Recursive Testing Scope:** Included in `[Category("Fast")]`, `[Category("CI")]`, `[Category("Sprint")]`, `[Category("Release")]`.

**Example Test Case 3: Signing Data with a Wallet Key**

*   **AI-Verifiable End Result Targeted:** Successful Core Operations, Secure Interactions, High Code Coverage, TDD Adherence.
*   **Unit Under Test:** `SigningService` (hypothetical)
*   **Interactions to Test:** The `SigningService`'s interaction with a key management component and a cryptographic library to sign data.
*   **Collaborators to Mock:** `IKeyManagementService` (hypothetical interface for key retrieval), `ICryptographicService` (hypothetical interface for signing operations).
*   **Expected Interactions with Mocks:** The `SigningService` should call `IKeyManagementService.GetKey(keyId)` to retrieve the signing key. It should then call `ICryptographicService.Sign(data, signingKey)` with the data to be signed and the retrieved key. The mock `ICryptographicService` should be configured to return a predefined signature.
*   **Observable Outcome:** The `SigningService.SignData(data, keyId)` method should return the expected signature.
*   **Recursive Testing Scope:** Included in `[Category("Fast")]`, `[Category("CI")]`, `[Category("Sprint")]`, `[Category("Release")]`, `[Category("Security")]`.

**Example Integration Test Case: Wallet Creation and Retrieval Flow**

*   **AI-Verifiable End Result Targeted:** Successful Core Operations, High Code Coverage.
*   **Components Under Test:** `WalletService` and `IWalletStorage` implementation (e.g., an in-memory or file-based implementation for integration tests).
*   **Scenario:** Create a new wallet using the `WalletService`, then retrieve it using the same service.
*   **Observable Outcome:** The retrieved wallet data should match the data used during creation.
*   **Recursive Testing Scope:** Included in `[Category("Sprint")]`, `[Category("Release")]`.

**Example BDD Test Case: User Creates and Accesses Wallet**

*   **AI-Verifiable End Result Targeted:** Successful Core Operations, TDD Adherence.
*   **Feature:** Wallet Management
*   **Scenario:** User successfully creates a wallet and can access it.
    *   Given the user is on the wallet creation screen
    *   When the user provides valid wallet details and confirms creation
    *   Then a new wallet should be created
    *   And the user should be able to access the wallet using the provided credentials
*   **Recursive Testing Scope:** Included in `[Category("Release")]`, `[Category("Scheduled")]`.

## 6. Test Environment

The test environment will be configured to support the layered testing strategy and London School principles:

*   **Mocking Framework:** Moq will be used extensively in unit tests to create mock objects for collaborators.
*   **Integration Test Setup:** Integration tests may require setting up specific environments, such as in-memory databases or test containers for external dependencies. WebApplicationFactory will be used for testing web-related components.
*   **Test Data:** Test data will be carefully prepared to cover various scenarios, including valid inputs, edge cases, and invalid inputs. FsCheck can assist in generating diverse test data for property-based testing.
*   **Configuration:** Test-specific configurations will be managed to ensure tests are isolated and repeatable.

## 7. Coverage Goals

The project aims for maximum code coverage for the WalletFrameworkCore. Coverlet will be used to measure code coverage, and the CI pipeline will be configured to enforce a minimum coverage threshold. The goal is to achieve as close to 100% line, branch, and method coverage as is practically feasible, focusing on critical paths and complex logic.

## 8. Tools

The following tools will be used in the testing process:

*   **xUnit:** The primary testing framework for unit and integration tests.
*   **Moq:** A mocking library for creating mock objects in unit tests.
*   **WebApplicationFactory:** Used for creating an in-memory test server for integration tests of ASP.NET Core components.
*   **SpecFlow:** A BDD framework for writing and executing end-to-end tests using Gherkin syntax.
*   **FsCheck:** A library for property-based testing.
*   **Coverlet:** A cross-platform code coverage tool for .NET.

This test plan provides a framework for testing the WalletFrameworkCore feature, aligning with the project's goals and emphasizing a robust, recursive testing strategy based on London School of TDD principles.